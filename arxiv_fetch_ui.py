import streamlit as st
import sys
import os
import requests
import xml.etree.ElementTree as ET

# --- æ¤œç´¢ãƒ‘ã‚¹ã«ä¸Šã®éšå±¤ã‚’è¿½åŠ ï¼ˆä»–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ç”¨ï¼‰ ---
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

# --- arXivè«–æ–‡å–å¾—é–¢æ•°ã®å®šç¾© ---
def fetch_arxiv_articles(query="natural language processing", max_results=10):
    url = f"http://export.arxiv.org/api/query?search_query=all:{query}&start=0&max_results={max_results}"
    response = requests.get(url)

    if response.status_code != 200:
        raise Exception(f"arXiv API error: {response.status_code}")

    root = ET.fromstring(response.content)
    ns = {"atom": "http://www.w3.org/2005/Atom"}

    results = []
    for entry in root.findall("atom:entry", ns):
        title = entry.find("atom:title", ns).text.strip()
        link = entry.find("atom:id", ns).text.strip()
        results.append({"title": title, "url": link})

    return results

# --- Streamlit UIå®šç¾© ---
st.set_page_config(page_title="arXivè«–æ–‡å–å¾—ãƒ„ãƒ¼ãƒ«", page_icon="ğŸ“„")
st.title("ğŸ“„ arXivè«–æ–‡å–å¾—ãƒ„ãƒ¼ãƒ«")

# æ¤œç´¢ãƒ•ã‚©ãƒ¼ãƒ 
query = st.text_input("ğŸ” æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ï¼ˆä¾‹: GPT, BERT, CD73ï¼‰", "natural language processing")
max_results = st.slider("å–å¾—ä»¶æ•°", min_value=1, max_value=50, value=10)

# æ¤œç´¢å®Ÿè¡Œ
if st.button("ğŸ“¥ è«–æ–‡ã‚’å–å¾—"):
    try:
        with st.spinner("è«–æ–‡ã‚’å–å¾—ä¸­..."):
            results = fetch_arxiv_articles(query, max_results)
        st.success(f"{len(results)} ä»¶ã®è«–æ–‡ã‚’å–å¾—ã—ã¾ã—ãŸï¼")

        for i, paper in enumerate(results, 1):
            st.markdown(f"**{i}. [{paper['title']}]({paper['url']})**")

    except Exception as e:
        st.error(f"å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
